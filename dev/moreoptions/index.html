<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>More options · GaussianVariationalInference</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="GaussianVariationalInference logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">GaussianVariationalInference</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>More options</a><ul class="internal"><li><a class="tocitem" href="#Specifying-gradient-options"><span>Specifying gradient options</span></a></li><li><a class="tocitem" href="#Evaluating-the-ELBO-on-test-samples"><span>Evaluating the ELBO on test samples</span></a></li><li><a class="tocitem" href="#Parallel-evaluation"><span>Parallel evaluation</span></a></li></ul></li><li><a class="tocitem" href="../technicaldescription/">Technical description</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>More options</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>More options</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ngiann/GaussianVariationalInference.jl/blob/master/docs/src/moreoptions.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h2 id="Specifying-gradient-options"><a class="docs-heading-anchor" href="#Specifying-gradient-options">Specifying gradient options</a><a id="Specifying-gradient-options-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-gradient-options" title="Permalink"></a></h2><p>Function <code>VI</code> allows the user to obtain a Gaussian approximation with minimal requirements. The user only needs to code a function <code>logp</code> that implements the log-posterior, provide an initial starting point <code>x₀</code> and call:</p><pre><code class="nohighlight hljs"># log-posterior is a Gaussian with zero mean and unit covariance.
# Hence, our approximation should be exact in this example.
logp(x) = -sum(x.*x) / 2

# initial point implicitly specifies that the log-posterior is 5-dimensional
x₀ = randn(5)

# obtain approximation
q, logev = VI(logp, x₀, S = 200, iterations = 10_000, show_every = 200)

# Check that mean is close to zero and covariance close to identity.
# mean and cov are re-exported function from Distributions.jl
mean(q)
cov(q)</code></pre><p>However, providing a gradient for <code>logp</code> can speed up the computation in <code>VI</code>.</p><h5 id="Gradient-free-mode"><a class="docs-heading-anchor" href="#Gradient-free-mode">➤  Gradient free mode</a><a id="Gradient-free-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-free-mode" title="Permalink"></a></h5><p><em>Specify by</em> <code>gradientmode = :gradientfree</code>.</p><p>If no options relating to the gradient are specified, i.e. none of the options <code>gradientmode</code> or <code>gradlogp</code> is specified, <code>VI</code> will by default use internally the <a href="https://julianlsolvers.github.io/Optim.jl/stable/#algo/nelder_mead/"><code>Optim.NelderMead</code></a> optimiser that does not need a gradient.  </p><p>The user can explicitly specify that <code>VI</code> should use the gradient free optimisation algorithm  <code>Optim.NelderMead</code> by setting <code>gradientmode = :gradientfree</code>.</p><h5 id="Automatic-differentiation-mode"><a class="docs-heading-anchor" href="#Automatic-differentiation-mode">➤  Automatic differentiation mode</a><a id="Automatic-differentiation-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-differentiation-mode" title="Permalink"></a></h5><p><em>Specify by</em> <code>gradientmode = :forward</code>.</p><p>If <code>logp</code> is coding a differentiable function<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, then its gradient can be conveniently computed using automatic differentiation. By specifying <code>gradientmode = :forward</code>, function <code>VI</code> will internally use <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff</a> to calculate the gradient of <code>logp</code>. In this case, <code>VI</code> will use internally the <a href="https://julianlsolvers.github.io/Optim.jl/stable/#algo/lbfgs/"><code>Optim.LBFGS</code></a> optimiser.</p><pre><code class="nohighlight hljs">q, logev = VI(logp, x₀, S = 200, iterations = 30, show_every = 1, gradientmode = :forward)</code></pre><p>We note that with the use of <code>gradientmode = :forward</code> we arrive in fewer iterations to a result than in the gradient free case.</p><h5 id="Gradient-provided"><a class="docs-heading-anchor" href="#Gradient-provided">➤  Gradient provided</a><a id="Gradient-provided-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-provided" title="Permalink"></a></h5><p><em>Specify by</em> <code>gradientmode = :provided</code>.</p><p>The user can provide a gradient for <code>logp</code> via the <code>gradlogp</code> option:</p><pre><code class="nohighlight hljs"># Let us calculate the gradient explicitly
gradlogp(x) = -x

q, logev = VI(logp, x₀, gradlogp = gradlogp, S = 200, iterations = 30, show_every = 1, gradientmode = :provided)</code></pre><p>In this case, <code>VI</code> will use internally the <a href="https://julianlsolvers.github.io/Optim.jl/stable/#algo/lbfgs/"><code>Optim.LBFGS</code></a> optimiser. Again in this case we arrive in fewer iterations to a result than in the gradient free case.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Even if a gradient has been explicitly provided via the <code>gradlogp</code> option, the user still needs to specify <code>gradientmode = :provided</code> to instruct <code>VI</code> to use the provided gradient.</p></div></div><h2 id="Evaluating-the-ELBO-on-test-samples"><a class="docs-heading-anchor" href="#Evaluating-the-ELBO-on-test-samples">Evaluating the ELBO on test samples</a><a id="Evaluating-the-ELBO-on-test-samples-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluating-the-ELBO-on-test-samples" title="Permalink"></a></h2><p>The option <code>S</code> specifies the number of samples to use when approximating the expected lower bound (ELBO), see <a href="../technicaldescription/#Technical-background">Technical background</a>. The higher the value we use for <code>S</code>, the better the approximation to the ELBO will be, but at a higher computational cost. The lower the value we use for <code>S</code>, the faster the computation will be, but the approximation to the ELBO may be poorer. Hence, when setting <code>S</code> we need to take this trade-off into account.</p><p>Function <code>VI</code> offers a mechanism that tests whether the value <code>S</code> is set to a sufficiently high value. This mechanism makes use of two options, namely <code>Stest</code> and <code>test_every</code>. Option <code>Stest</code> defines a number of test samples used exclusively for evaluating (<em>not optimising!</em>) and reporting the ELBO every <code>test_every</code> number of iterations, see <a href="../technicaldescription/#ELBO-maximisation">ELBO maximisation</a>.  If <code>S</code> is set sufficiently high, then we should see that as the ELBO increases, so does the ELBO on the test samples. If on the other hand, we notice that the ELBO on the test samples is decreasing, then this is a clear sign that a larger <span>$S$</span> is required.</p><p>Monitoring the ELBO this way is an effective way of detecting whether <code>S</code> has been set sufficiently high.</p><p>The following code snippet shows how to specify the options <code>Stest</code> and <code>test_every</code>:</p><pre><code class="nohighlight hljs"># Use 2000 test samples and report test ELBO every 20 iterations
q, logev = VI(logp, x₀, S = 200, iterations = 1000, Stest = 2000, test_every = 20)</code></pre><p>If the test ELBO at the current iteration is small than in the previous iteration, it is printed out in red colour. An additional example can be found here <a href="../examples/#Monitoring-ELBO">Monitoring ELBO</a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Whenever option <code>Stest</code> is set, <code>test_every</code> must be set to.</p></div></div><h2 id="Parallel-evaluation"><a class="docs-heading-anchor" href="#Parallel-evaluation">Parallel evaluation</a><a id="Parallel-evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-evaluation" title="Permalink"></a></h2><p>The package makes use of <a href="https://github.com/JuliaFolds/Transducers.jl">Transducers.jl</a> in order to parallelise the evaluation of the lower bound and its gradient on a number of threads. In order to make use of this feature, simply start julia by specifying a number of threads e.g. <code>julia -t4</code>.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>The implementation of the function needs to satisfy certain requirements, see <a href="https://juliadiff.org/ForwardDiff.jl/stable/user/limitations/">here</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Introduction</a><a class="docs-footer-nextpage" href="../technicaldescription/">Technical description »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Thursday 20 July 2023 06:53">Thursday 20 July 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
